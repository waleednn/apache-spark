== Physical Plan ==
* Sort (51)
+- Exchange (50)
   +- * Project (49)
      +- * BroadcastHashJoin Inner BuildRight (48)
         :- * Project (23)
         :  +- * BroadcastHashJoin Inner BuildRight (22)
         :     :- * HashAggregate (16)
         :     :  +- Exchange (15)
         :     :     +- * HashAggregate (14)
         :     :        +- * Project (13)
         :     :           +- * BroadcastHashJoin Inner BuildRight (12)
         :     :              :- Union (7)
         :     :              :  :- * Project (3)
         :     :              :  :  +- * ColumnarToRow (2)
         :     :              :  :     +- Scan parquet spark_catalog.default.web_sales (1)
         :     :              :  +- * Project (6)
         :     :              :     +- * ColumnarToRow (5)
         :     :              :        +- Scan parquet spark_catalog.default.catalog_sales (4)
         :     :              +- BroadcastExchange (11)
         :     :                 +- * Filter (10)
         :     :                    +- * ColumnarToRow (9)
         :     :                       +- Scan parquet spark_catalog.default.date_dim (8)
         :     +- BroadcastExchange (21)
         :        +- * Project (20)
         :           +- * Filter (19)
         :              +- * ColumnarToRow (18)
         :                 +- Scan parquet spark_catalog.default.date_dim (17)
         +- BroadcastExchange (47)
            +- * Project (46)
               +- * BroadcastHashJoin Inner BuildRight (45)
                  :- * HashAggregate (39)
                  :  +- Exchange (38)
                  :     +- * HashAggregate (37)
                  :        +- * Project (36)
                  :           +- * BroadcastHashJoin Inner BuildRight (35)
                  :              :- Union (30)
                  :              :  :- * Project (26)
                  :              :  :  +- * ColumnarToRow (25)
                  :              :  :     +- Scan parquet spark_catalog.default.web_sales (24)
                  :              :  +- * Project (29)
                  :              :     +- * ColumnarToRow (28)
                  :              :        +- Scan parquet spark_catalog.default.catalog_sales (27)
                  :              +- BroadcastExchange (34)
                  :                 +- * Filter (33)
                  :                    +- * ColumnarToRow (32)
                  :                       +- Scan parquet spark_catalog.default.date_dim (31)
                  +- BroadcastExchange (44)
                     +- * Project (43)
                        +- * Filter (42)
                           +- * ColumnarToRow (41)
                              +- Scan parquet spark_catalog.default.date_dim (40)


(1) Scan parquet spark_catalog.default.web_sales
Output [2]: [ws_ext_sales_price#1, ws_sold_date_sk#2]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#2)]
ReadSchema: struct<ws_ext_sales_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 1]
Input [2]: [ws_ext_sales_price#1, ws_sold_date_sk#2]

(3) Project [codegen id : 1]
Output [2]: [ws_sold_date_sk#2 AS sold_date_sk#3, ws_ext_sales_price#1 AS sales_price#4]
Input [2]: [ws_ext_sales_price#1, ws_sold_date_sk#2]

(4) Scan parquet spark_catalog.default.catalog_sales
Output [2]: [cs_ext_sales_price#5, cs_sold_date_sk#6]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#6)]
ReadSchema: struct<cs_ext_sales_price:decimal(7,2)>

(5) ColumnarToRow [codegen id : 2]
Input [2]: [cs_ext_sales_price#5, cs_sold_date_sk#6]

(6) Project [codegen id : 2]
Output [2]: [cs_sold_date_sk#6 AS sold_date_sk#7, cs_ext_sales_price#5 AS sales_price#8]
Input [2]: [cs_ext_sales_price#5, cs_sold_date_sk#6]

(7) Union

(8) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#9, d_week_seq#10, d_day_name#11]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)]
ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>

(9) ColumnarToRow [codegen id : 3]
Input [3]: [d_date_sk#9, d_week_seq#10, d_day_name#11]

(10) Filter [codegen id : 3]
Input [3]: [d_date_sk#9, d_week_seq#10, d_day_name#11]
Condition : ((isnotnull(d_date_sk#9) AND isnotnull(d_week_seq#10)) AND might_contain(Subquery scalar-subquery#12, [id=#13].bloomFilter, xxhash64(d_week_seq#10, 42)))

(11) BroadcastExchange
Input [3]: [d_date_sk#9, d_week_seq#10, d_day_name#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(12) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [sold_date_sk#3]
Right keys [1]: [d_date_sk#9]
Join type: Inner
Join condition: None

(13) Project [codegen id : 4]
Output [3]: [sales_price#4, d_week_seq#10, d_day_name#11]
Input [5]: [sold_date_sk#3, sales_price#4, d_date_sk#9, d_week_seq#10, d_day_name#11]

(14) HashAggregate [codegen id : 4]
Input [3]: [sales_price#4, d_week_seq#10, d_day_name#11]
Keys [1]: [d_week_seq#10]
Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Sunday   ) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Monday   ) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Tuesday  ) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Wednesday) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Thursday ) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Friday   ) THEN sales_price#4 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#11 = Saturday ) THEN sales_price#4 END))]
Aggregate Attributes [7]: [sum#14, sum#15, sum#16, sum#17, sum#18, sum#19, sum#20]
Results [8]: [d_week_seq#10, sum#21, sum#22, sum#23, sum#24, sum#25, sum#26, sum#27]

(15) Exchange
Input [8]: [d_week_seq#10, sum#21, sum#22, sum#23, sum#24, sum#25, sum#26, sum#27]
Arguments: hashpartitioning(d_week_seq#10, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(16) HashAggregate [codegen id : 12]
Input [8]: [d_week_seq#10, sum#21, sum#22, sum#23, sum#24, sum#25, sum#26, sum#27]
Keys [1]: [d_week_seq#10]
Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#11 = Sunday   ) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Monday   ) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Tuesday  ) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Wednesday) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Thursday ) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Friday   ) THEN sales_price#4 END)), sum(UnscaledValue(CASE WHEN (d_day_name#11 = Saturday ) THEN sales_price#4 END))]
Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#11 = Sunday   ) THEN sales_price#4 END))#28, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Monday   ) THEN sales_price#4 END))#29, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Tuesday  ) THEN sales_price#4 END))#30, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Wednesday) THEN sales_price#4 END))#31, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Thursday ) THEN sales_price#4 END))#32, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Friday   ) THEN sales_price#4 END))#33, sum(UnscaledValue(CASE WHEN (d_day_name#11 = Saturday ) THEN sales_price#4 END))#34]
Results [8]: [d_week_seq#10, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Sunday   ) THEN sales_price#4 END))#28,17,2) AS sun_sales#35, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Monday   ) THEN sales_price#4 END))#29,17,2) AS mon_sales#36, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Tuesday  ) THEN sales_price#4 END))#30,17,2) AS tue_sales#37, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Wednesday) THEN sales_price#4 END))#31,17,2) AS wed_sales#38, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Thursday ) THEN sales_price#4 END))#32,17,2) AS thu_sales#39, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Friday   ) THEN sales_price#4 END))#33,17,2) AS fri_sales#40, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#11 = Saturday ) THEN sales_price#4 END))#34,17,2) AS sat_sales#41]

(17) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_week_seq#42, d_year#43]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2001), IsNotNull(d_week_seq)]
ReadSchema: struct<d_week_seq:int,d_year:int>

(18) ColumnarToRow [codegen id : 5]
Input [2]: [d_week_seq#42, d_year#43]

(19) Filter [codegen id : 5]
Input [2]: [d_week_seq#42, d_year#43]
Condition : ((isnotnull(d_year#43) AND (d_year#43 = 2001)) AND isnotnull(d_week_seq#42))

(20) Project [codegen id : 5]
Output [1]: [d_week_seq#42]
Input [2]: [d_week_seq#42, d_year#43]

(21) BroadcastExchange
Input [1]: [d_week_seq#42]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(22) BroadcastHashJoin [codegen id : 12]
Left keys [1]: [d_week_seq#10]
Right keys [1]: [d_week_seq#42]
Join type: Inner
Join condition: None

(23) Project [codegen id : 12]
Output [8]: [d_week_seq#10 AS d_week_seq1#44, sun_sales#35 AS sun_sales1#45, mon_sales#36 AS mon_sales1#46, tue_sales#37 AS tue_sales1#47, wed_sales#38 AS wed_sales1#48, thu_sales#39 AS thu_sales1#49, fri_sales#40 AS fri_sales1#50, sat_sales#41 AS sat_sales1#51]
Input [9]: [d_week_seq#10, sun_sales#35, mon_sales#36, tue_sales#37, wed_sales#38, thu_sales#39, fri_sales#40, sat_sales#41, d_week_seq#42]

(24) Scan parquet spark_catalog.default.web_sales
Output [2]: [ws_ext_sales_price#52, ws_sold_date_sk#53]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#53)]
ReadSchema: struct<ws_ext_sales_price:decimal(7,2)>

(25) ColumnarToRow [codegen id : 6]
Input [2]: [ws_ext_sales_price#52, ws_sold_date_sk#53]

(26) Project [codegen id : 6]
Output [2]: [ws_sold_date_sk#53 AS sold_date_sk#54, ws_ext_sales_price#52 AS sales_price#55]
Input [2]: [ws_ext_sales_price#52, ws_sold_date_sk#53]

(27) Scan parquet spark_catalog.default.catalog_sales
Output [2]: [cs_ext_sales_price#56, cs_sold_date_sk#57]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#57)]
ReadSchema: struct<cs_ext_sales_price:decimal(7,2)>

(28) ColumnarToRow [codegen id : 7]
Input [2]: [cs_ext_sales_price#56, cs_sold_date_sk#57]

(29) Project [codegen id : 7]
Output [2]: [cs_sold_date_sk#57 AS sold_date_sk#58, cs_ext_sales_price#56 AS sales_price#59]
Input [2]: [cs_ext_sales_price#56, cs_sold_date_sk#57]

(30) Union

(31) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#60, d_week_seq#61, d_day_name#62]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)]
ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>

(32) ColumnarToRow [codegen id : 8]
Input [3]: [d_date_sk#60, d_week_seq#61, d_day_name#62]

(33) Filter [codegen id : 8]
Input [3]: [d_date_sk#60, d_week_seq#61, d_day_name#62]
Condition : ((isnotnull(d_date_sk#60) AND isnotnull(d_week_seq#61)) AND might_contain(ReusedSubquery Subquery scalar-subquery#12, [id=#13].bloomFilter, xxhash64(d_week_seq#61, 42)))

(34) BroadcastExchange
Input [3]: [d_date_sk#60, d_week_seq#61, d_day_name#62]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=4]

(35) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [sold_date_sk#54]
Right keys [1]: [d_date_sk#60]
Join type: Inner
Join condition: None

(36) Project [codegen id : 9]
Output [3]: [sales_price#55, d_week_seq#61, d_day_name#62]
Input [5]: [sold_date_sk#54, sales_price#55, d_date_sk#60, d_week_seq#61, d_day_name#62]

(37) HashAggregate [codegen id : 9]
Input [3]: [sales_price#55, d_week_seq#61, d_day_name#62]
Keys [1]: [d_week_seq#61]
Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Sunday   ) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Monday   ) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Tuesday  ) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Wednesday) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Thursday ) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Friday   ) THEN sales_price#55 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#62 = Saturday ) THEN sales_price#55 END))]
Aggregate Attributes [7]: [sum#63, sum#64, sum#65, sum#66, sum#67, sum#68, sum#69]
Results [8]: [d_week_seq#61, sum#70, sum#71, sum#72, sum#73, sum#74, sum#75, sum#76]

(38) Exchange
Input [8]: [d_week_seq#61, sum#70, sum#71, sum#72, sum#73, sum#74, sum#75, sum#76]
Arguments: hashpartitioning(d_week_seq#61, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(39) HashAggregate [codegen id : 11]
Input [8]: [d_week_seq#61, sum#70, sum#71, sum#72, sum#73, sum#74, sum#75, sum#76]
Keys [1]: [d_week_seq#61]
Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#62 = Sunday   ) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Monday   ) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Tuesday  ) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Wednesday) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Thursday ) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Friday   ) THEN sales_price#55 END)), sum(UnscaledValue(CASE WHEN (d_day_name#62 = Saturday ) THEN sales_price#55 END))]
Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#62 = Sunday   ) THEN sales_price#55 END))#28, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Monday   ) THEN sales_price#55 END))#29, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Tuesday  ) THEN sales_price#55 END))#30, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Wednesday) THEN sales_price#55 END))#31, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Thursday ) THEN sales_price#55 END))#32, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Friday   ) THEN sales_price#55 END))#33, sum(UnscaledValue(CASE WHEN (d_day_name#62 = Saturday ) THEN sales_price#55 END))#34]
Results [8]: [d_week_seq#61, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Sunday   ) THEN sales_price#55 END))#28,17,2) AS sun_sales#77, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Monday   ) THEN sales_price#55 END))#29,17,2) AS mon_sales#78, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Tuesday  ) THEN sales_price#55 END))#30,17,2) AS tue_sales#79, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Wednesday) THEN sales_price#55 END))#31,17,2) AS wed_sales#80, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Thursday ) THEN sales_price#55 END))#32,17,2) AS thu_sales#81, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Friday   ) THEN sales_price#55 END))#33,17,2) AS fri_sales#82, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#62 = Saturday ) THEN sales_price#55 END))#34,17,2) AS sat_sales#83]

(40) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_week_seq#84, d_year#85]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2002), IsNotNull(d_week_seq)]
ReadSchema: struct<d_week_seq:int,d_year:int>

(41) ColumnarToRow [codegen id : 10]
Input [2]: [d_week_seq#84, d_year#85]

(42) Filter [codegen id : 10]
Input [2]: [d_week_seq#84, d_year#85]
Condition : ((isnotnull(d_year#85) AND (d_year#85 = 2002)) AND isnotnull(d_week_seq#84))

(43) Project [codegen id : 10]
Output [1]: [d_week_seq#84]
Input [2]: [d_week_seq#84, d_year#85]

(44) BroadcastExchange
Input [1]: [d_week_seq#84]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

(45) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [d_week_seq#61]
Right keys [1]: [d_week_seq#84]
Join type: Inner
Join condition: None

(46) Project [codegen id : 11]
Output [8]: [d_week_seq#61 AS d_week_seq2#86, sun_sales#77 AS sun_sales2#87, mon_sales#78 AS mon_sales2#88, tue_sales#79 AS tue_sales2#89, wed_sales#80 AS wed_sales2#90, thu_sales#81 AS thu_sales2#91, fri_sales#82 AS fri_sales2#92, sat_sales#83 AS sat_sales2#93]
Input [9]: [d_week_seq#61, sun_sales#77, mon_sales#78, tue_sales#79, wed_sales#80, thu_sales#81, fri_sales#82, sat_sales#83, d_week_seq#84]

(47) BroadcastExchange
Input [8]: [d_week_seq2#86, sun_sales2#87, mon_sales2#88, tue_sales2#89, wed_sales2#90, thu_sales2#91, fri_sales2#92, sat_sales2#93]
Arguments: HashedRelationBroadcastMode(List(cast((input[0, int, true] - 53) as bigint)),false), [plan_id=7]

(48) BroadcastHashJoin [codegen id : 12]
Left keys [1]: [d_week_seq1#44]
Right keys [1]: [(d_week_seq2#86 - 53)]
Join type: Inner
Join condition: None

(49) Project [codegen id : 12]
Output [8]: [d_week_seq1#44, round((sun_sales1#45 / sun_sales2#87), 2) AS round((sun_sales1 / sun_sales2), 2)#94, round((mon_sales1#46 / mon_sales2#88), 2) AS round((mon_sales1 / mon_sales2), 2)#95, round((tue_sales1#47 / tue_sales2#89), 2) AS round((tue_sales1 / tue_sales2), 2)#96, round((wed_sales1#48 / wed_sales2#90), 2) AS round((wed_sales1 / wed_sales2), 2)#97, round((thu_sales1#49 / thu_sales2#91), 2) AS round((thu_sales1 / thu_sales2), 2)#98, round((fri_sales1#50 / fri_sales2#92), 2) AS round((fri_sales1 / fri_sales2), 2)#99, round((sat_sales1#51 / sat_sales2#93), 2) AS round((sat_sales1 / sat_sales2), 2)#100]
Input [16]: [d_week_seq1#44, sun_sales1#45, mon_sales1#46, tue_sales1#47, wed_sales1#48, thu_sales1#49, fri_sales1#50, sat_sales1#51, d_week_seq2#86, sun_sales2#87, mon_sales2#88, tue_sales2#89, wed_sales2#90, thu_sales2#91, fri_sales2#92, sat_sales2#93]

(50) Exchange
Input [8]: [d_week_seq1#44, round((sun_sales1 / sun_sales2), 2)#94, round((mon_sales1 / mon_sales2), 2)#95, round((tue_sales1 / tue_sales2), 2)#96, round((wed_sales1 / wed_sales2), 2)#97, round((thu_sales1 / thu_sales2), 2)#98, round((fri_sales1 / fri_sales2), 2)#99, round((sat_sales1 / sat_sales2), 2)#100]
Arguments: rangepartitioning(d_week_seq1#44 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(51) Sort [codegen id : 13]
Input [8]: [d_week_seq1#44, round((sun_sales1 / sun_sales2), 2)#94, round((mon_sales1 / mon_sales2), 2)#95, round((tue_sales1 / tue_sales2), 2)#96, round((wed_sales1 / wed_sales2), 2)#97, round((thu_sales1 / thu_sales2), 2)#98, round((fri_sales1 / fri_sales2), 2)#99, round((sat_sales1 / sat_sales2), 2)#100]
Arguments: [d_week_seq1#44 ASC NULLS FIRST], true, 0

===== Subqueries =====

Subquery:1 Hosting operator id = 10 Hosting Expression = Subquery scalar-subquery#12, [id=#13]
* Project (59)
+- ObjectHashAggregate (58)
   +- Exchange (57)
      +- ObjectHashAggregate (56)
         +- * Project (55)
            +- * Filter (54)
               +- * ColumnarToRow (53)
                  +- Scan parquet spark_catalog.default.date_dim (52)


(52) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_week_seq#42, d_year#43]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_week_seq), Or(EqualTo(d_year,2001),EqualTo(d_year,2002))]
ReadSchema: struct<d_week_seq:int,d_year:int>

(53) ColumnarToRow [codegen id : 1]
Input [2]: [d_week_seq#42, d_year#43]

(54) Filter [codegen id : 1]
Input [2]: [d_week_seq#42, d_year#43]
Condition : ((isnotnull(d_year#43) AND isnotnull(d_week_seq#42)) AND ((d_year#43 = 2001) OR (d_year#43 = 2002)))

(55) Project [codegen id : 1]
Output [3]: [d_week_seq#42, ((isnotnull(d_year#43) AND (d_year#43 = 2001)) AND isnotnull(d_week_seq#42)) AS propagatedFilter#101, ((isnotnull(d_year#43) AND (d_year#43 = 2002)) AND isnotnull(d_week_seq#42)) AS propagatedFilter#102]
Input [2]: [d_week_seq#42, d_year#43]

(56) ObjectHashAggregate
Input [3]: [d_week_seq#42, propagatedFilter#101, propagatedFilter#102]
Keys: []
Functions [2]: [partial_bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0) FILTER (WHERE propagatedFilter#101), partial_bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0) FILTER (WHERE propagatedFilter#102)]
Aggregate Attributes [2]: [buf#103, buf#104]
Results [2]: [buf#105, buf#106]

(57) Exchange
Input [2]: [buf#105, buf#106]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9]

(58) ObjectHashAggregate
Input [2]: [buf#105, buf#106]
Keys: []
Functions [2]: [bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0), bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0)]
Aggregate Attributes [2]: [bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0)#107, bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0)#108]
Results [2]: [bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0)#107 AS bloomFilter#109, bloom_filter_agg(xxhash64(d_week_seq#42, 42), 362, 9656, 0, 0)#108 AS bloomFilter#110]

(59) Project [codegen id : 2]
Output [1]: [named_struct(bloomFilter, bloomFilter#109, bloomFilter, bloomFilter#110) AS mergedValue#111]
Input [2]: [bloomFilter#109, bloomFilter#110]

Subquery:2 Hosting operator id = 33 Hosting Expression = ReusedSubquery Subquery scalar-subquery#12, [id=#13]


